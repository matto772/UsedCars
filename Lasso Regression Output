> # Add a dummy target variable 'car_cost' for illustration (replace with actual data)
> set.seed(123)  # For reproducibility
> x$car_cost <- 20000 - 100 * x$model_year + 0.5 * x$milage + rnorm(nrow(x), mean = 0, sd = 500)
> 
> # Prepare data for Lasso regression
> # Extract predictors and target variable
> X <- model.matrix(car_cost ~ model_year + milage, data = x)[, -1]  # Remove intercept
> y <- x$car_cost
> 
> # Split data into training and testing sets
> set.seed(123)
> train_index <- sample(1:nrow(x), size = 0.8 * nrow(x))
> X_train <- X[train_index, ]
> X_test <- X[-train_index, ]
> y_train <- y[train_index]
> y_test <- y[-train_index]
> 
> # Fit Lasso regression model
> lasso_model <- cv.glmnet(X_train, y_train, alpha = 1, nfolds = 10)  # Lasso (alpha = 1)
> 
> # Best lambda value from cross-validation
> best_lambda <- lasso_model$lambda.min
> cat("Best Lambda:", best_lambda, "\n")
Best Lambda: 475.9186 
> 
> # Plot cross-validation results
> plot(lasso_model)
> 
> # Make predictions on the test set
> y_pred <- predict(lasso_model, s = best_lambda, newx = X_test)
> 
> # Evaluate model performance
> mse <- mean((y_test - y_pred)^2)
> cat("Mean Squared Error (MSE) on Test Data:", mse, "\n")
Mean Squared Error (MSE) on Test Data: 509451.8 
> 
> # Check coefficients of the model
> lasso_coefficients <- coef(lasso_model, s = best_lambda)
> print("Coefficients:")
[1] "Coefficients:"
> print(lasso_coefficients)
3 x 1 sparse Matrix of class "dgCMatrix"
                       s1
(Intercept) -9.353344e+04
model_year  -4.350555e+01
milage       4.940262e-01
